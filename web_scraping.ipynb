#Web scrapping:
# !pip install requests
# !pip install pandas
# !pip install beautifulsoup4

url='https://www.worldometers.info/coronavirus/'
import requests
response=requests.get(url)
print(response)

response.content

from bs4 import BeautifulSoup
soup=BeautifulSoup(response.content,'html.parser')
print(soup)

print(soup.prettify()[:5000])

title_text=soup.select('title')

title_text[0].getText() #getText to extract text

para_text=soup.select('style')
para_text[0].getText()

data=soup.find("tbody").find_all('tr')
data

for world_data in data:
  print(world_data)
  break

complete=[]
for i in range(8,len(data)):
  world_data=[]
  list_data=data[i].find_all('td')
  for col in list_data:
    world_data.append(col.getText())
  complete.append(world_data)

complete[0]

complete[0][1:10]

complete[0][12]

complete[0][14]

mapped_data=list(map(lambda x:x[1:10]+[x[12]]+[x[14]],complete))
mapped_data

column_names=[
    'Name','Total_cases','New cases','Total deaths','New deaths','Total recovered','New recovered','Active cases','Serious cases','Total tests','Population'
]

cc=len(mapped_data[0])
c=len(column_names)

print(complete[:2])

import pandas as pd
df=pd.DataFrame(mapped_data,columns=column_names)
df.head(25)

df.tail()

#Saving to CSV file:
df.to_csv("COVID_DATA.csv",index=False) #Do it only once or else the data will be over written.

df_read=pd.read_csv('COVID_DATA.csv')
type(df_read)

#axis=0,axis=1
df_read.isnull()

df_read.isnull().sum()

df_read.iloc[25:75]

df_read.isnull().sum(axis=1)

missing_data=df_read.isnull().sum()
print(missing_data)
print(type(missing_data))

#Data Plotting:
#Heatmap
import  seaborn as sns
sns.heatmap(df_read.isnull().T)


#Plotting in python
missing_data.plot(kind='bar')

import matplotlib.pyplot as plt
missing_data.plot(kind='barh')
plt.title("Missing Data count")
#plt.show()
plt.xlabel("Number of missing data")
plt.ylabel("Data group")
plt.show()

#Using plotly:
missing_data.values

missing_data.index

import plotly.express as px
px.bar(x=missing_data.index,y=missing_data.values)

#Pie chart:
px.pie(values=missing_data.values,names=missing_data.index)

df.head()

df.dtypes

#Data Preprocessing:
#Correct data format
df['Total_cases']=df['Total_cases'].map(lambda x:int(x.replace(",","")))

df['Total_cases']

df_cases_country=df.sort_values(by='Total_cases',ascending=False)
df_cases_country.head()


df_cases_country=df_cases_country.set_index('Name')
df_cases_country.head()

df_cases_country['Total_cases'].head().plot(kind='bar')

px.bar(x=df_cases_country.index,y=df_cases_country['Total_cases'])

#zip:
country=['Nepal','USA','India']
capital=['Kathmandu','NY','Delhi']
for c,cap in zip(country,capital):
  print(c,' â†’',cap)

#Save the visualised data in sqlite:

import sqlite3
db_name = 'Data.db'
conn = sqlite3.connect(db_name)
print("Database created and connection is setup!!")

# create database table

conn.execute(""" CREATE TABLE Covid
            (
             ID             INT           PRIMARY KEY           NOT NULL,
             NAMES          VARCHAR(50)                         NOT NULL,
             TOTALCASES     VARCHAR(50)                        NOT NULL,
             TOTALDEATHS     VARCHAR(50),
             TOTALRECOVERED  VARCHAR(50),
             TOTALTESTS      VARCHAR(50)
            )
             """)

for idx,row in df.iterrows():
  names = row['Name']
  total_cases = row['Total_cases']
  total_deaths = row['Total deaths']
  total_recovered = row['Total recovered']
  total_tests = row['Total tests']

  try:
    conn.execute(f""" INSERT INTO
            covid_stats (ID, NAMES, TOTALCASES, TOTALDEATHS, TOTALRECOVERED, TOTALTESTS) VALUES ('{idx}', '{names}', '{total_cases}', '{total_deaths}', '{total_recovered}', '{total_tests}')
    """)

  except Exception as e:
    print(f'{row} already inserted')

  else:
    conn.commit()
